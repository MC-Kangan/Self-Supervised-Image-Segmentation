{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# Import torch vision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a simple dataset for testing model architecture\n",
    "# import the cifar10 dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the image height and width for resizing the images to input the model\n",
    "# As the pytorch resnet model requires the input image to be 224x224 ,even with pre-trained weights equal False\n",
    "# we will resize the images to 224x224, as size bigger than 224x224 will be cropped to 224x224\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "def get_color_distortion(s=1.0):\n",
    "    # s is the strength of color distortion.\n",
    "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
    "    rnd_gray = transforms.RandomGrayscale(p=0.2)\n",
    "    color_distort = transforms.Compose([\n",
    "    rnd_color_jitter,\n",
    "    rnd_gray])\n",
    "    return color_distort\n",
    "# This is the best combination of data augmentation techniques for the SimCLR model shown in the paper\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((image_height, image_width)), # This follow the random cropping and resizing in the paper\n",
    "    get_color_distortion(s=1),\n",
    "    transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0)), # In the paper, the kernel size is 10% of the image height and width and sigma is between 0.1 and 2.0. As the kernel size must be odd, we choose 23 as the kernel size.\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the loss function for SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent_loss(queries, keys, temperature = 0.1):\n",
    "    b, device = queries.shape[0], queries.device\n",
    "\n",
    "    n = b * 2  # 同一图片内部不同patch也是负样本\n",
    "    projs = torch.cat((queries, keys))\n",
    "    logits = projs @ projs.t()\n",
    "\n",
    "    mask = torch.eye(n, device=device).bool()\n",
    "    logits = logits[~mask].reshape(n, n - 1)  # 同一图片内部不同patch也是负样本，除了自己和自己\n",
    "    logits /= temperature\n",
    "\n",
    "    labels = torch.cat(((torch.arange(b, device = device) + b - 1), torch.arange(b, device=device)), dim=0)\n",
    "    loss = F.cross_entropy(logits, labels, reduction = 'sum')\n",
    "    loss /= n\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the backbone model f(.) to train on the data augmentation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/miniconda3/envs/ADL/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/matthew/miniconda3/envs/ADL/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "# Import resnet50 model from torchvision\n",
    "from torchvision.models import resnet50\n",
    "# Load the resnet50 model which returns the features before the classification layer\n",
    "model = resnet50(pretrained=False) # Optionally, you can set pretrained=True to use the pre-trained weights\n",
    "# return the features before the classification layer\n",
    "model.fc = nn.Identity() # Remove the classification layer\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "# get the output shape of the model by passing a random tensor of the image size\n",
    "print(model(torch.randn(1, 3, image_height, image_width)).shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, model, temperature=0.1):\n",
    "        super(SimCLR, self).__init__()\n",
    "        # get the device of the model\n",
    "        self.model = model\n",
    "        # This is the two-layer MLP projection head as described in the paper whcih represents the g(.) function\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "        self.temperature = temperature\n",
    "        # Define the cosine similarity function\n",
    "        # cosine_similarity = lambda z_i, z_j: torch.dot(z_i, z_j) / (torch.norm(z_i) * torch.norm(z_j))\n",
    "    def forward(self, x):\n",
    "        h = self.model(x)\n",
    "        print(h.shape)\n",
    "        z_i = self.projection_head(h)\n",
    "        print(z_i.shape)\n",
    "        z_j = self.projection_head(h)\n",
    "        # get the normalized projection head output\n",
    "        # z_i = nn.functional.normalize(z_i, dim=1)\n",
    "        # z_j = nn.functional.normalize(z_j, dim=1)\n",
    "\n",
    "        # Loss calculation by nt_xent_loss function\n",
    "        loss = nt_xent_loss(z_i, z_j, self.temperature)\n",
    "        return loss\n",
    "# Create the SimCLR model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Lars optimizer from scratch \n",
    "# As the the coursework limit to use of 4 external libraries, we will implement the LARS optimizer from scratch\n",
    "\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "import re\n",
    "\n",
    "EETA_DEFAULT = 0.001\n",
    "\n",
    "\n",
    "class LARS(Optimizer):\n",
    "    \"\"\"\n",
    "    Layer-wise Adaptive Rate Scaling for large batch training.\n",
    "    Introduced by \"Large Batch Training of Convolutional Networks\" by Y. You,\n",
    "    I. Gitman, and B. Ginsburg. (https://arxiv.org/abs/1708.03888)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,\n",
    "        lr=required,\n",
    "        momentum=0.9,\n",
    "        use_nesterov=False,\n",
    "        weight_decay=0.0,\n",
    "        exclude_from_weight_decay=None,\n",
    "        exclude_from_layer_adaptation=None,\n",
    "        classic_momentum=True,\n",
    "        eeta=EETA_DEFAULT,\n",
    "    ):\n",
    "        \"\"\"Constructs a LARSOptimizer.\n",
    "        Args:\n",
    "        lr: A `float` for learning rate.\n",
    "        momentum: A `float` for momentum.\n",
    "        use_nesterov: A 'Boolean' for whether to use nesterov momentum.\n",
    "        weight_decay: A `float` for weight decay.\n",
    "        exclude_from_weight_decay: A list of `string` for variable screening, if\n",
    "            any of the string appears in a variable's name, the variable will be\n",
    "            excluded for computing weight decay. For example, one could specify\n",
    "            the list like ['batch_normalization', 'bias'] to exclude BN and bias\n",
    "            from weight decay.\n",
    "        exclude_from_layer_adaptation: Similar to exclude_from_weight_decay, but\n",
    "            for layer adaptation. If it is None, it will be defaulted the same as\n",
    "            exclude_from_weight_decay.\n",
    "        classic_momentum: A `boolean` for whether to use classic (or popular)\n",
    "            momentum. The learning rate is applied during momeuntum update in\n",
    "            classic momentum, but after momentum for popular momentum.\n",
    "        eeta: A `float` for scaling of learning rate when computing trust ratio.\n",
    "        name: The name for the scope.\n",
    "        \"\"\"\n",
    "\n",
    "        self.epoch = 0\n",
    "        defaults = dict(\n",
    "            lr=lr,\n",
    "            momentum=momentum,\n",
    "            use_nesterov=use_nesterov,\n",
    "            weight_decay=weight_decay,\n",
    "            exclude_from_weight_decay=exclude_from_weight_decay,\n",
    "            exclude_from_layer_adaptation=exclude_from_layer_adaptation,\n",
    "            classic_momentum=classic_momentum,\n",
    "            eeta=eeta,\n",
    "        )\n",
    "\n",
    "        super(LARS, self).__init__(params, defaults)\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "        self.use_nesterov = use_nesterov\n",
    "        self.classic_momentum = classic_momentum\n",
    "        self.eeta = eeta\n",
    "        self.exclude_from_weight_decay = exclude_from_weight_decay\n",
    "        # exclude_from_layer_adaptation is set to exclude_from_weight_decay if the\n",
    "        # arg is None.\n",
    "        if exclude_from_layer_adaptation:\n",
    "            self.exclude_from_layer_adaptation = exclude_from_layer_adaptation\n",
    "        else:\n",
    "            self.exclude_from_layer_adaptation = exclude_from_weight_decay\n",
    "\n",
    "    def step(self, epoch=None, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        if epoch is None:\n",
    "            epoch = self.epoch\n",
    "            self.epoch += 1\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "            eeta = group[\"eeta\"]\n",
    "            lr = group[\"lr\"]\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                param = p.data\n",
    "                grad = p.grad.data\n",
    "\n",
    "                param_state = self.state[p]\n",
    "\n",
    "                # TODO: get param names\n",
    "                # if self._use_weight_decay(param_name):\n",
    "                grad += self.weight_decay * param\n",
    "\n",
    "                if self.classic_momentum:\n",
    "                    trust_ratio = 1.0\n",
    "\n",
    "                    # TODO: get param names\n",
    "                    # if self._do_layer_adaptation(param_name):\n",
    "                    w_norm = torch.norm(param)\n",
    "                    g_norm = torch.norm(grad)\n",
    "\n",
    "                    device = g_norm.get_device()\n",
    "                    trust_ratio = torch.where(\n",
    "                        w_norm.gt(0),\n",
    "                        torch.where(\n",
    "                            g_norm.gt(0),\n",
    "                            (self.eeta * w_norm / g_norm),\n",
    "                            torch.Tensor([1.0]).to(device),\n",
    "                        ),\n",
    "                        torch.Tensor([1.0]).to(device),\n",
    "                    ).item()\n",
    "\n",
    "                    scaled_lr = lr * trust_ratio\n",
    "                    if \"momentum_buffer\" not in param_state:\n",
    "                        next_v = param_state[\"momentum_buffer\"] = torch.zeros_like(\n",
    "                            p.data\n",
    "                        )\n",
    "                    else:\n",
    "                        next_v = param_state[\"momentum_buffer\"]\n",
    "\n",
    "                    next_v.mul_(momentum).add_(scaled_lr, grad)\n",
    "                    if self.use_nesterov:\n",
    "                        update = (self.momentum * next_v) + (scaled_lr * grad)\n",
    "                    else:\n",
    "                        update = next_v\n",
    "\n",
    "                    p.data.add_(-update)\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _use_weight_decay(self, param_name):\n",
    "        \"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"\n",
    "        if not self.weight_decay:\n",
    "            return False\n",
    "        if self.exclude_from_weight_decay:\n",
    "            for r in self.exclude_from_weight_decay:\n",
    "                if re.search(r, param_name) is not None:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def _do_layer_adaptation(self, param_name):\n",
    "        \"\"\"Whether to do layer-wise learning rate adaptation for `param_name`.\"\"\"\n",
    "        if self.exclude_from_layer_adaptation:\n",
    "            for r in self.exclude_from_layer_adaptation:\n",
    "                if re.search(r, param_name) is not None:\n",
    "                    return False\n",
    "        return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/miniconda3/envs/ADL/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3084/3399654239.py:132: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/torch/csrc/utils/python_arg_parser.cpp:1630.)\n",
      "  next_v.mul_(momentum).add_(scaled_lr, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(100.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(19.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(6.8337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(4.7816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(4.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(4.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(4.0212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(4.7296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.8195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.5439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.5362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.7038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.6430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.6792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.6010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.5515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(4.5880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(4.1973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(4.3071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.4190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.9465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.7214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.5334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.7528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(4.4451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(4.9052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.6881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([64, 2048])\n",
      "torch.Size([64, 128])\n",
      "tensor(3.2525, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Start the training loop for SimCLR\n",
    "model = resnet50(pretrained=False)\n",
    "model.fc = nn.Identity()\n",
    "simclr_model = SimCLR(model)\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 30\n",
    "\n",
    "# define the dataset and dataloader\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=data_transforms, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# move the model to the device\n",
    "model = model.to(device)  \n",
    "simclr_model = simclr_model.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = LARS(\n",
    "    [params for params in model.parameters() if params.requires_grad],\n",
    "    lr=0.2,\n",
    "    weight_decay=1e-6,\n",
    "    exclude_from_weight_decay=[\"batch_normalization\", \"bias\"],\n",
    ")\n",
    "\n",
    "# Start the training loop for SimCLR\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        images, _ = data\n",
    "        images = images.to(device)\n",
    "        # Perform the forward pass\n",
    "        loss = simclr_model(images)\n",
    "        # Perform the backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
